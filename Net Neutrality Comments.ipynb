{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net Neutrality Comments\n",
    "\n",
    "a first pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm curious to see some things about these large datasets:\n",
    "- can we classify the responses by for/against?\n",
    "- how many addresses/names are repeated?\n",
    "- how similar are the responses to one another?\n",
    "- what are the time of day / seasonal trends?\n",
    "- sentiment analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying duplicates\n",
    "\n",
    "In the spirit of identifying duplicates, we could parse the comments and look for comments filed by the same person multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Comment(object):\n",
    "    def __init__(self, comment):\n",
    "        \"\"\"expect that the comment is already parsed from json\n",
    "        \"\"\"\n",
    "        self.address = comment['addressentity']\n",
    "        self.email = comment['contact_email']\n",
    "        self.received = comment['date_received']\n",
    "        self.name = comment['filers'][0]['name']\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return (self.name == other.name and self.address == other.address) or self.email == other.email\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash((self.email, self.name, self.address['address_line_1'], self.address['city'], self.address['zip_code']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%pdb\n",
    "\n",
    "TOTAL_TO_PROCESS = 100000\n",
    "COMMENTS = []\n",
    "\n",
    "processed = 0\n",
    "\n",
    "THIRD_DIR = './ECFS_17-108_3'\n",
    "for dir_, _, file_list in os.walk(THIRD_DIR):\n",
    "    for file in file_list:\n",
    "        if processed >= TOTAL_TO_PROCESS:\n",
    "            break\n",
    "        with open(os.path.join(THIRD_DIR, file), 'r') as f:\n",
    "            for comment in json.loads(f.read()):\n",
    "                if processed < TOTAL_TO_PROCESS:\n",
    "                    try:\n",
    "                        COMMENTS.append(Comment(comment))\n",
    "                    except:\n",
    "                        # TODO: handle edge cases better\n",
    "                        continue\n",
    "                    processed += 1\n",
    "                else:\n",
    "                    break\n",
    "                if processed % 1000 == 0:\n",
    "                    print(f'processed {processed} files')\n",
    "\n",
    "COMMENTS[0]\n",
    "\n",
    "reduced = set(COMMENTS)\n",
    "\n",
    "len(reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing comment text\n",
    "\n",
    "- what are the most common words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n",
      "processing file ecfs_17-108_21910000.json\n",
      "processed 1000 comments\n",
      "processed 2000 comments\n",
      "processed 3000 comments\n",
      "processed 4000 comments\n",
      "processed 5000 comments\n",
      "processed 6000 comments\n",
      "processed 7000 comments\n",
      "processed 8000 comments\n",
      "processed 9000 comments\n",
      "processed 10000 comments\n",
      "processing file ecfs_17-108_21900000.json\n",
      "processed 11000 comments\n",
      "processed 12000 comments\n",
      "processed 13000 comments\n",
      "processed 14000 comments\n",
      "processed 15000 comments\n",
      "processed 16000 comments\n",
      "processed 17000 comments\n",
      "processed 18000 comments\n",
      "processed 19000 comments\n",
      "processed 20000 comments\n",
      "processing file ecfs_17-108_18660000.json\n",
      "processed 21000 comments\n",
      "processed 22000 comments\n",
      "processed 23000 comments\n",
      "processed 24000 comments\n",
      "processed 25000 comments\n",
      "processed 26000 comments\n",
      "processed 27000 comments\n",
      "processed 28000 comments\n",
      "processed 29000 comments\n",
      "processed 30000 comments\n",
      "processing file ecfs_17-108_16900000.json\n",
      "processed 31000 comments\n",
      "processed 32000 comments\n",
      "processed 33000 comments\n",
      "processed 34000 comments\n",
      "processed 35000 comments\n",
      "processed 36000 comments\n",
      "processed 37000 comments\n",
      "processed 38000 comments\n",
      "processed 39000 comments\n",
      "processed 40000 comments\n",
      "processing file ecfs_17-108_16910000.json\n",
      "processed 41000 comments\n",
      "processed 42000 comments\n",
      "processed 43000 comments\n",
      "processed 44000 comments\n",
      "processed 45000 comments\n",
      "processed 46000 comments\n",
      "processed 47000 comments\n",
      "processed 48000 comments\n",
      "processed 49000 comments\n",
      "processed 50000 comments\n",
      "processing file ecfs_17-108_18670000.json\n",
      "processed 51000 comments\n",
      "processed 52000 comments\n",
      "processed 53000 comments\n",
      "processed 54000 comments\n",
      "processed 55000 comments\n",
      "processed 56000 comments\n",
      "processed 57000 comments\n",
      "processed 58000 comments\n",
      "processed 59000 comments\n",
      "processed 60000 comments\n",
      "processing file ecfs_17-108_21030000.json\n",
      "processed 61000 comments\n",
      "processed 62000 comments\n",
      "processed 63000 comments\n",
      "processed 64000 comments\n",
      "processed 65000 comments\n",
      "processed 66000 comments\n",
      "processed 67000 comments\n",
      "processed 68000 comments\n",
      "processed 69000 comments\n",
      "processed 70000 comments\n",
      "processing file ecfs_17-108_21020000.json\n",
      "processed 71000 comments\n",
      "processed 72000 comments\n",
      "processed 73000 comments\n",
      "processed 74000 comments\n",
      "processed 75000 comments\n",
      "processed 76000 comments\n",
      "processed 77000 comments\n",
      "processed 78000 comments\n",
      "processed 79000 comments\n",
      "processed 80000 comments\n",
      "processing file ecfs_17-108_16020000.json\n",
      "processed 81000 comments\n",
      "processed 82000 comments\n",
      "processed 83000 comments\n",
      "processed 84000 comments\n",
      "processed 85000 comments\n",
      "processed 86000 comments\n",
      "processed 87000 comments\n",
      "processed 88000 comments\n",
      "processed 89000 comments\n",
      "processed 90000 comments\n",
      "processing file ecfs_17-108_16030000.json\n",
      "processed 91000 comments\n",
      "processed 92000 comments\n",
      "processed 93000 comments\n",
      "processed 94000 comments\n",
      "processed 95000 comments\n",
      "processed 96000 comments\n",
      "processed 97000 comments\n",
      "processed 98000 comments\n",
      "processed 99000 comments\n",
      "processed 100000 comments\n",
      "processing file ecfs_17-108_20990000.json\n",
      "processed 101000 comments\n",
      "processed 102000 comments\n",
      "processed 103000 comments\n",
      "processed 104000 comments\n",
      "processed 105000 comments\n",
      "processed 106000 comments\n",
      "processed 107000 comments\n",
      "processed 108000 comments\n",
      "processed 109000 comments\n",
      "processed 110000 comments\n",
      "processing file ecfs_17-108_20980000.json\n",
      "processed 111000 comments\n",
      "processed 112000 comments\n",
      "processed 113000 comments\n",
      "processed 114000 comments\n",
      "processed 115000 comments\n",
      "processed 116000 comments\n",
      "processed 117000 comments\n",
      "processed 118000 comments\n",
      "processed 119000 comments\n",
      "processed 120000 comments\n",
      "processing file ecfs_17-108_17980000.json\n",
      "processed 121000 comments\n",
      "processed 122000 comments\n",
      "processed 123000 comments\n",
      "processed 124000 comments\n",
      "processed 125000 comments\n",
      "processed 126000 comments\n",
      "processed 127000 comments\n",
      "processed 128000 comments\n",
      "processed 129000 comments\n",
      "processing file ecfs_17-108_17990000.json\n",
      "processed 130000 comments\n",
      "processed 131000 comments\n",
      "processed 132000 comments\n",
      "processed 133000 comments\n",
      "processed 134000 comments\n",
      "processed 135000 comments\n",
      "processed 136000 comments\n",
      "processed 137000 comments\n",
      "processed 138000 comments\n",
      "processed 139000 comments\n",
      "processing file ecfs_17-108_17430000.json\n",
      "processed 140000 comments\n",
      "processed 141000 comments\n",
      "processed 142000 comments\n",
      "processed 143000 comments\n",
      "processed 144000 comments\n",
      "processed 145000 comments\n",
      "processed 146000 comments\n",
      "processed 147000 comments\n",
      "processed 148000 comments\n",
      "processed 149000 comments\n",
      "processing file ecfs_17-108_15250000.json\n",
      "processed 150000 comments\n",
      "processed 151000 comments\n",
      "processed 152000 comments\n",
      "processed 153000 comments\n",
      "processed 154000 comments\n",
      "processed 155000 comments\n",
      "processed 156000 comments\n",
      "processed 157000 comments\n",
      "processed 158000 comments\n",
      "processed 159000 comments\n",
      "processing file ecfs_17-108_15240000.json\n",
      "processed 160000 comments\n",
      "processed 161000 comments\n",
      "processed 162000 comments\n",
      "processed 163000 comments\n",
      "processed 164000 comments\n",
      "processed 165000 comments\n",
      "processed 166000 comments\n",
      "processed 167000 comments\n",
      "processed 168000 comments\n",
      "processed 169000 comments\n",
      "processing file ecfs_17-108_17420000.json\n",
      "processed 170000 comments\n",
      "processed 171000 comments\n",
      "processed 172000 comments\n",
      "processed 173000 comments\n",
      "processed 174000 comments\n",
      "processed 175000 comments\n",
      "processed 176000 comments\n",
      "processed 177000 comments\n",
      "processed 178000 comments\n",
      "processed 179000 comments\n",
      "processing file ecfs_17-108_20420000.json\n",
      "processed 180000 comments\n",
      "processed 181000 comments\n",
      "processed 182000 comments\n",
      "processed 183000 comments\n",
      "processed 184000 comments\n",
      "processed 185000 comments\n",
      "processed 186000 comments\n",
      "processed 187000 comments\n",
      "processed 188000 comments\n",
      "processed 189000 comments\n",
      "processing file ecfs_17-108_20430000.json\n",
      "processed 190000 comments\n",
      "processed 191000 comments\n",
      "processed 192000 comments\n",
      "processed 193000 comments\n",
      "processed 194000 comments\n",
      "processed 195000 comments\n",
      "processed 196000 comments\n",
      "processed 197000 comments\n",
      "processed 198000 comments\n",
      "processed 199000 comments\n",
      "processing file ecfs_17-108_19270000.json\n",
      "processed 200000 comments\n",
      "processed 201000 comments\n",
      "processed 202000 comments\n",
      "processed 203000 comments\n",
      "processed 204000 comments\n",
      "processed 205000 comments\n",
      "processed 206000 comments\n",
      "processed 207000 comments\n",
      "processed 208000 comments\n",
      "processed 209000 comments\n",
      "processing file ecfs_17-108_19260000.json\n",
      "processed 210000 comments\n",
      "processed 211000 comments\n",
      "processed 212000 comments\n",
      "processed 213000 comments\n",
      "processed 214000 comments\n",
      "processed 215000 comments\n",
      "processed 216000 comments\n",
      "processed 217000 comments\n",
      "processed 218000 comments\n",
      "processed 219000 comments\n",
      "processing file ecfs_17-108_18580000.json\n",
      "processed 220000 comments\n",
      "processed 221000 comments\n",
      "processed 222000 comments\n",
      "processed 223000 comments\n",
      "processed 224000 comments\n",
      "processed 225000 comments\n",
      "processed 226000 comments\n",
      "processed 227000 comments\n",
      "processed 228000 comments\n",
      "processed 229000 comments\n",
      "processing file ecfs_17-108_18590000.json\n",
      "processed 230000 comments\n",
      "processed 231000 comments\n",
      "processed 232000 comments\n",
      "processed 233000 comments\n",
      "processed 234000 comments\n",
      "processed 235000 comments\n",
      "processed 236000 comments\n",
      "processed 237000 comments\n",
      "processed 238000 comments\n",
      "processed 239000 comments\n",
      "processing file ecfs_17-108_15520000.json\n",
      "processed 240000 comments\n",
      "processed 241000 comments\n",
      "processed 242000 comments\n",
      "processed 243000 comments\n",
      "processed 244000 comments\n",
      "processed 245000 comments\n",
      "processed 246000 comments\n",
      "processed 247000 comments\n",
      "processed 248000 comments\n",
      "processed 249000 comments\n",
      "processing file ecfs_17-108_17340000.json\n",
      "processed 250000 comments\n",
      "processed 251000 comments\n",
      "processed 252000 comments\n",
      "processed 253000 comments\n",
      "processed 254000 comments\n",
      "processed 255000 comments\n",
      "processed 256000 comments\n",
      "processed 257000 comments\n",
      "processed 258000 comments\n",
      "processed 259000 comments\n",
      "processing file ecfs_17-108_17350000.json\n",
      "processed 260000 comments\n",
      "processed 261000 comments\n",
      "processed 262000 comments\n",
      "processed 263000 comments\n",
      "processed 264000 comments\n",
      "processed 265000 comments\n",
      "processed 266000 comments\n",
      "processed 267000 comments\n",
      "processed 268000 comments\n",
      "processed 269000 comments\n",
      "processing file ecfs_17-108_15530000.json\n",
      "processed 270000 comments\n",
      "processed 271000 comments\n",
      "processed 272000 comments\n",
      "processed 273000 comments\n",
      "processed 274000 comments\n",
      "processed 275000 comments\n",
      "processed 276000 comments\n",
      "processed 277000 comments\n",
      "processed 278000 comments\n",
      "processed 279000 comments\n",
      "processing file ecfs_17-108_20350000.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 280000 comments\n",
      "processed 281000 comments\n",
      "processed 282000 comments\n",
      "processed 283000 comments\n",
      "processed 284000 comments\n",
      "processed 285000 comments\n",
      "processed 286000 comments\n",
      "processed 287000 comments\n",
      "processed 288000 comments\n",
      "processed 289000 comments\n",
      "processing file ecfs_17-108_20340000.json\n",
      "processed 290000 comments\n",
      "processed 291000 comments\n",
      "processed 292000 comments\n",
      "processed 293000 comments\n",
      "processed 294000 comments\n",
      "processed 295000 comments\n",
      "processed 296000 comments\n",
      "processed 297000 comments\n",
      "processed 298000 comments\n",
      "processed 299000 comments\n",
      "processing file ecfs_17-108_19500000.json\n",
      "processed 300000 comments\n",
      "processed 301000 comments\n",
      "processed 302000 comments\n",
      "processed 303000 comments\n",
      "processed 304000 comments\n",
      "processed 305000 comments\n",
      "processed 306000 comments\n",
      "processed 307000 comments\n",
      "processed 308000 comments\n",
      "processed 309000 comments\n",
      "processing file ecfs_17-108_19510000.json\n",
      "processed 310000 comments\n",
      "processed 311000 comments\n",
      "processed 312000 comments\n",
      "processed 313000 comments\n",
      "processed 314000 comments\n",
      "processed 315000 comments\n",
      "processed 316000 comments\n",
      "processed 317000 comments\n",
      "processed 318000 comments\n",
      "processed 319000 comments\n",
      "processing file ecfs_17-108_18110000.json\n",
      "processed 320000 comments\n",
      "processed 321000 comments\n",
      "processed 322000 comments\n",
      "processed 323000 comments\n",
      "processed 324000 comments\n",
      "processed 325000 comments\n",
      "processed 326000 comments\n",
      "processed 327000 comments\n",
      "processed 328000 comments\n",
      "processed 329000 comments\n",
      "processing file ecfs_17-108_14810000.json\n",
      "processed 330000 comments\n",
      "processed 331000 comments\n",
      "processed 332000 comments\n",
      "processed 333000 comments\n",
      "processed 334000 comments\n",
      "processed 335000 comments\n",
      "processed 336000 comments\n",
      "processed 337000 comments\n",
      "processed 338000 comments\n",
      "processed 339000 comments\n",
      "processing file ecfs_17-108_18100000.json\n",
      "processed 340000 comments\n",
      "processed 341000 comments\n",
      "processed 342000 comments\n",
      "processed 343000 comments\n",
      "processed 344000 comments\n",
      "processed 345000 comments\n",
      "processed 346000 comments\n",
      "processed 347000 comments\n",
      "processed 348000 comments\n",
      "processed 349000 comments\n",
      "processing file ecfs_17-108_14800000.json\n",
      "processed 350000 comments\n",
      "processed 351000 comments\n",
      "processed 352000 comments\n",
      "processed 353000 comments\n",
      "processed 354000 comments\n",
      "processed 355000 comments\n",
      "processed 356000 comments\n",
      "processed 357000 comments\n",
      "processed 358000 comments\n",
      "processed 359000 comments\n",
      "processing file ecfs_17-108_21740000.json\n",
      "processed 360000 comments\n",
      "processed 361000 comments\n",
      "processed 362000 comments\n",
      "processed 363000 comments\n",
      "processed 364000 comments\n",
      "processed 365000 comments\n",
      "processed 366000 comments\n",
      "processed 367000 comments\n",
      "processed 368000 comments\n",
      "processed 369000 comments\n",
      "processing file ecfs_17-108_21750000.json\n",
      "processed 370000 comments\n",
      "processed 371000 comments\n",
      "processed 372000 comments\n",
      "processed 373000 comments\n",
      "processed 374000 comments\n",
      "processed 375000 comments\n",
      "processed 376000 comments\n",
      "processed 377000 comments\n",
      "processed 378000 comments\n",
      "processed 379000 comments\n",
      "processing file ecfs_17-108_16750000.json\n",
      "processed 380000 comments\n",
      "processed 381000 comments\n",
      "processed 382000 comments\n",
      "processed 383000 comments\n",
      "processed 384000 comments\n",
      "processed 385000 comments\n",
      "processed 386000 comments\n",
      "processed 387000 comments\n",
      "processed 388000 comments\n",
      "processed 389000 comments\n",
      "processing file ecfs_17-108_18830000.json\n",
      "processed 390000 comments\n",
      "processed 391000 comments\n",
      "processed 392000 comments\n",
      "processed 393000 comments\n",
      "processed 394000 comments\n",
      "processed 395000 comments\n",
      "processed 396000 comments\n",
      "processed 397000 comments\n",
      "processed 398000 comments\n",
      "processed 399000 comments\n",
      "processing file ecfs_17-108_18820000.json\n",
      "processed 400000 comments\n",
      "processed 401000 comments\n",
      "processed 402000 comments\n",
      "processed 403000 comments\n",
      "processed 404000 comments\n",
      "processed 405000 comments\n",
      "processed 406000 comments\n",
      "processed 407000 comments\n",
      "processed 408000 comments\n",
      "processed 409000 comments\n",
      "processing file ecfs_17-108_16740000.json\n",
      "processed 410000 comments\n",
      "processed 411000 comments\n",
      "processed 412000 comments\n",
      "processed 413000 comments\n",
      "processed 414000 comments\n",
      "processed 415000 comments\n",
      "processed 416000 comments\n",
      "processed 417000 comments\n",
      "processed 418000 comments\n",
      "processed 419000 comments\n",
      "processing file ecfs_17-108_15890000.json\n",
      "processed 420000 comments\n",
      "processed 421000 comments\n",
      "processed 422000 comments\n",
      "processed 423000 comments\n",
      "processed 424000 comments\n",
      "processed 425000 comments\n",
      "processed 426000 comments\n",
      "processed 427000 comments\n",
      "processed 428000 comments\n",
      "processed 429000 comments\n",
      "processing file ecfs_17-108_19190000.json\n",
      "processed 430000 comments\n",
      "processed 431000 comments\n",
      "processed 432000 comments\n",
      "processed 433000 comments\n",
      "processed 434000 comments\n",
      "processed 435000 comments\n",
      "processed 436000 comments\n",
      "processed 437000 comments\n",
      "processed 438000 comments\n",
      "processed 439000 comments\n",
      "processing file ecfs_17-108_15880000.json\n",
      "processed 440000 comments\n",
      "processed 441000 comments\n",
      "processed 442000 comments\n",
      "processed 443000 comments\n",
      "processed 444000 comments\n",
      "processed 445000 comments\n",
      "processed 446000 comments\n",
      "processed 447000 comments\n",
      "processed 448000 comments\n",
      "processed 449000 comments\n",
      "processing file ecfs_17-108_19180000.json\n",
      "processed 450000 comments\n",
      "processed 451000 comments\n",
      "processed 452000 comments\n",
      "processed 453000 comments\n",
      "processed 454000 comments\n",
      "processed 455000 comments\n",
      "processed 456000 comments\n",
      "processed 457000 comments\n",
      "processed 458000 comments\n",
      "processed 459000 comments\n",
      "processing file ecfs_17-108_16410000.json\n",
      "processed 460000 comments\n",
      "processed 461000 comments\n",
      "processed 462000 comments\n",
      "processed 463000 comments\n",
      "processed 464000 comments\n",
      "processed 465000 comments\n",
      "processed 466000 comments\n",
      "processed 467000 comments\n",
      "processed 468000 comments\n",
      "processed 469000 comments\n",
      "processing file ecfs_17-108_16400000.json\n",
      "processed 470000 comments\n",
      "processed 471000 comments\n",
      "processed 472000 comments\n",
      "processed 473000 comments\n",
      "processed 474000 comments\n",
      "processed 475000 comments\n",
      "processed 476000 comments\n",
      "processed 477000 comments\n",
      "processed 478000 comments\n",
      "processed 479000 comments\n",
      "processing file ecfs_17-108_21400000.json\n",
      "processed 480000 comments\n",
      "processed 481000 comments\n",
      "processed 482000 comments\n",
      "processed 483000 comments\n",
      "processed 484000 comments\n",
      "processed 485000 comments\n",
      "processed 486000 comments\n",
      "processed 487000 comments\n",
      "processed 488000 comments\n",
      "processed 489000 comments\n",
      "processing file ecfs_17-108_21410000.json\n",
      "processed 490000 comments\n",
      "processed 491000 comments\n",
      "processed 492000 comments\n",
      "processed 493000 comments\n",
      "processed 494000 comments\n",
      "processed 495000 comments\n",
      "processed 496000 comments\n",
      "processed 497000 comments\n",
      "processed 498000 comments\n",
      "processed 499000 comments\n",
      "processing file ecfs_17-108_17490000.json\n",
      "processed 500000 comments\n",
      "processed 501000 comments\n",
      "processed 502000 comments\n",
      "processed 503000 comments\n",
      "processed 504000 comments\n",
      "processed 505000 comments\n",
      "processed 506000 comments\n",
      "processed 507000 comments\n",
      "processed 508000 comments\n",
      "processed 509000 comments\n",
      "processing file ecfs_17-108_17480000.json\n",
      "processed 510000 comments\n",
      "processed 511000 comments\n",
      "processed 512000 comments\n",
      "processed 513000 comments\n",
      "processed 514000 comments\n",
      "processed 515000 comments\n",
      "processed 516000 comments\n",
      "processed 517000 comments\n",
      "processed 518000 comments\n",
      "processed 519000 comments\n",
      "processing file ecfs_17-108_20480000.json\n",
      "processed 520000 comments\n",
      "processed 521000 comments\n",
      "processed 522000 comments\n",
      "processed 523000 comments\n",
      "processed 524000 comments\n",
      "processed 525000 comments\n",
      "processed 526000 comments\n",
      "processed 527000 comments\n",
      "processed 528000 comments\n",
      "processed 529000 comments\n",
      "processing file ecfs_17-108_20490000.json\n",
      "processed 530000 comments\n",
      "processed 531000 comments\n",
      "processed 532000 comments\n",
      "processed 533000 comments\n",
      "processed 534000 comments\n",
      "processed 535000 comments\n",
      "processed 536000 comments\n",
      "processed 537000 comments\n",
      "processed 538000 comments\n",
      "processed 539000 comments\n",
      "processing file ecfs_17-108_18250000.json\n",
      "processed 540000 comments\n",
      "processed 541000 comments\n",
      "processed 542000 comments\n",
      "processed 543000 comments\n",
      "processed 544000 comments\n",
      "processed 545000 comments\n",
      "processed 546000 comments\n",
      "processed 547000 comments\n",
      "processed 548000 comments\n",
      "processed 549000 comments\n",
      "processing file ecfs_17-108_18240000.json\n",
      "processed 550000 comments\n",
      "processed 551000 comments\n",
      "processed 552000 comments\n",
      "processed 553000 comments\n",
      "processed 554000 comments\n",
      "processed 555000 comments\n",
      "processed 556000 comments\n",
      "processed 557000 comments\n",
      "processed 558000 comments\n",
      "processed 559000 comments\n",
      "processing file ecfs_17-108_20930000.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 560000 comments\n",
      "processed 561000 comments\n",
      "processed 562000 comments\n",
      "processed 563000 comments\n",
      "processed 564000 comments\n",
      "processed 565000 comments\n",
      "processed 566000 comments\n",
      "processed 567000 comments\n",
      "processed 568000 comments\n",
      "processed 569000 comments\n",
      "processing file ecfs_17-108_20920000.json\n",
      "processed 570000 comments\n",
      "processed 571000 comments\n",
      "processed 572000 comments\n",
      "processed 573000 comments\n",
      "processed 574000 comments\n",
      "processed 575000 comments\n",
      "processed 576000 comments\n",
      "processed 577000 comments\n",
      "processed 578000 comments\n",
      "processed 579000 comments\n",
      "processing file ecfs_17-108_19640000.json\n",
      "processed 580000 comments\n",
      "processed 581000 comments\n",
      "processed 582000 comments\n",
      "processed 583000 comments\n",
      "processed 584000 comments\n",
      "processed 585000 comments\n",
      "processed 586000 comments\n",
      "processed 587000 comments\n",
      "processed 588000 comments\n",
      "processed 589000 comments\n",
      "processing file ecfs_17-108_17920000.json\n",
      "processed 590000 comments\n",
      "processed 591000 comments\n",
      "processed 592000 comments\n",
      "processed 593000 comments\n",
      "processed 594000 comments\n",
      "processed 595000 comments\n",
      "processed 596000 comments\n",
      "processed 597000 comments\n",
      "processed 598000 comments\n",
      "processed 599000 comments\n",
      "processing file ecfs_17-108_17930000.json\n",
      "processed 600000 comments\n",
      "processed 601000 comments\n",
      "processed 602000 comments\n",
      "processed 603000 comments\n",
      "processed 604000 comments\n",
      "processed 605000 comments\n",
      "processed 606000 comments\n",
      "processed 607000 comments\n",
      "processed 608000 comments\n",
      "processed 609000 comments\n",
      "processing file ecfs_17-108_19650000.json\n",
      "processed 610000 comments\n",
      "processed 611000 comments\n",
      "processed 612000 comments\n",
      "processed 613000 comments\n",
      "processed 614000 comments\n",
      "processed 615000 comments\n",
      "processed 616000 comments\n",
      "processed 617000 comments\n",
      "processed 618000 comments\n",
      "processed 619000 comments\n",
      "processing file ecfs_17-108_21090000.json\n",
      "processed 620000 comments\n",
      "processed 621000 comments\n",
      "processed 622000 comments\n",
      "processed 623000 comments\n",
      "processed 624000 comments\n",
      "processed 625000 comments\n",
      "processed 626000 comments\n",
      "processed 627000 comments\n",
      "processed 628000 comments\n",
      "processed 629000 comments\n",
      "processing file ecfs_17-108_21080000.json\n",
      "processed 630000 comments\n",
      "processed 631000 comments\n",
      "processed 632000 comments\n",
      "processed 633000 comments\n",
      "processed 634000 comments\n",
      "processed 635000 comments\n",
      "processed 636000 comments\n",
      "processed 637000 comments\n",
      "processed 638000 comments\n",
      "processed 639000 comments\n",
      "processing file ecfs_17-108_16080000.json\n",
      "processed 640000 comments\n",
      "processed 641000 comments\n",
      "processed 642000 comments\n",
      "processed 643000 comments\n",
      "processed 644000 comments\n",
      "processed 645000 comments\n",
      "processed 646000 comments\n",
      "processed 647000 comments\n",
      "processed 648000 comments\n",
      "processed 649000 comments\n",
      "processing file ecfs_17-108_16090000.json\n",
      "processed 650000 comments\n",
      "processed 651000 comments\n",
      "processed 652000 comments\n",
      "processed 653000 comments\n",
      "processed 654000 comments\n",
      "processed 655000 comments\n",
      "processed 656000 comments\n",
      "processed 657000 comments\n",
      "processed 658000 comments\n",
      "processed 659000 comments\n",
      "processing file ecfs_17-108_20010000.json\n",
      "processed 660000 comments\n",
      "processed 661000 comments\n",
      "processed 662000 comments\n",
      "processed 663000 comments\n",
      "processed 664000 comments\n",
      "processed 665000 comments\n",
      "processed 666000 comments\n",
      "processed 667000 comments\n",
      "processed 668000 comments\n",
      "processed 669000 comments\n",
      "processing file ecfs_17-108_20000000.json\n",
      "processed 670000 comments\n",
      "processed 671000 comments\n",
      "processed 672000 comments\n",
      "processed 673000 comments\n",
      "processed 674000 comments\n",
      "processed 675000 comments\n",
      "processed 676000 comments\n",
      "processed 677000 comments\n",
      "processed 678000 comments\n",
      "processed 679000 comments\n",
      "processing file ecfs_17-108_15660000.json\n",
      "processed 680000 comments\n",
      "processed 681000 comments\n",
      "processed 682000 comments\n",
      "processed 683000 comments\n",
      "processed 684000 comments\n",
      "processed 685000 comments\n",
      "processed 686000 comments\n",
      "processed 687000 comments\n",
      "processed 688000 comments\n",
      "processed 689000 comments\n",
      "processing file ecfs_17-108_17000000.json\n",
      "processed 690000 comments\n",
      "processed 691000 comments\n",
      "processed 692000 comments\n",
      "processed 693000 comments\n",
      "processed 694000 comments\n",
      "processed 695000 comments\n",
      "processed 696000 comments\n",
      "processed 697000 comments\n",
      "processed 698000 comments\n",
      "processed 699000 comments\n",
      "processing file ecfs_17-108_17010000.json\n",
      "processed 700000 comments\n",
      "processed 701000 comments\n",
      "processed 702000 comments\n",
      "processed 703000 comments\n",
      "processed 704000 comments\n",
      "processed 705000 comments\n",
      "processed 706000 comments\n",
      "processed 707000 comments\n",
      "processed 708000 comments\n",
      "processed 709000 comments\n",
      "processing file ecfs_17-108_15670000.json\n",
      "processed 710000 comments\n",
      "processed 711000 comments\n",
      "processed 712000 comments\n",
      "processed 713000 comments\n",
      "processed 714000 comments\n",
      "processed 715000 comments\n",
      "processed 716000 comments\n",
      "processed 717000 comments\n",
      "processed 718000 comments\n",
      "processed 719000 comments\n",
      "processing file ecfs_17-108_19130000.json\n",
      "processed 720000 comments\n",
      "processed 721000 comments\n",
      "processed 722000 comments\n",
      "processed 723000 comments\n",
      "processed 724000 comments\n",
      "processed 725000 comments\n",
      "processed 726000 comments\n",
      "processed 727000 comments\n",
      "processed 728000 comments\n",
      "processed 729000 comments\n",
      "processing file ecfs_17-108_15830000.json\n",
      "processed 730000 comments\n",
      "processed 731000 comments\n",
      "processed 732000 comments\n",
      "processed 733000 comments\n",
      "processed 734000 comments\n",
      "processed 735000 comments\n",
      "processed 736000 comments\n",
      "processed 737000 comments\n",
      "processed 738000 comments\n",
      "processed 739000 comments\n",
      "processing file ecfs_17-108_19120000.json\n",
      "processed 740000 comments\n",
      "processed 741000 comments\n",
      "processed 742000 comments\n",
      "processed 743000 comments\n",
      "processed 744000 comments\n",
      "processed 745000 comments\n",
      "processed 746000 comments\n",
      "processed 747000 comments\n",
      "processed 748000 comments\n",
      "processed 749000 comments\n",
      "processing file ecfs_17-108_15820000.json\n",
      "processed 750000 comments\n",
      "processed 751000 comments\n",
      "processed 752000 comments\n",
      "processed 753000 comments\n",
      "processed 754000 comments\n",
      "processed 755000 comments\n",
      "processed 756000 comments\n",
      "processed 757000 comments\n",
      "processed 758000 comments\n",
      "processed 759000 comments\n",
      "processing file ecfs_17-108_18890000.json\n",
      "processed 760000 comments\n",
      "processed 761000 comments\n",
      "processed 762000 comments\n",
      "processed 763000 comments\n",
      "processed 764000 comments\n",
      "processed 765000 comments\n",
      "processed 766000 comments\n",
      "processed 767000 comments\n",
      "processed 768000 comments\n",
      "processed 769000 comments\n",
      "processing file ecfs_17-108_18880000.json\n",
      "processed 770000 comments\n",
      "processed 771000 comments\n",
      "processed 772000 comments\n",
      "processed 773000 comments\n",
      "processed 774000 comments\n",
      "processed 775000 comments\n",
      "processed 776000 comments\n",
      "processed 777000 comments\n",
      "processed 778000 comments\n",
      "processed 779000 comments\n",
      "processing file ecfs_17-108_22100000.json\n",
      "processed 780000 comments\n",
      "processed 781000 comments\n",
      "processed 782000 comments\n",
      "processed 783000 comments\n",
      "processed 784000 comments\n",
      "processed 785000 comments\n",
      "processed 786000 comments\n",
      "processed 787000 comments\n",
      "processed 788000 comments\n",
      "processed 789000 comments\n",
      "processing file ecfs_17-108_20760000.json\n",
      "processed 790000 comments\n",
      "processed 791000 comments\n",
      "processed 792000 comments\n",
      "processed 793000 comments\n",
      "processed 794000 comments\n",
      "processed 795000 comments\n",
      "processed 796000 comments\n",
      "processed 797000 comments\n",
      "processed 798000 comments\n",
      "processed 799000 comments\n",
      "processing file ecfs_17-108_20770000.json\n",
      "processed 800000 comments\n",
      "processed 801000 comments\n",
      "processed 802000 comments\n",
      "processed 803000 comments\n",
      "processed 804000 comments\n",
      "processed 805000 comments\n",
      "processed 806000 comments\n",
      "processed 807000 comments\n",
      "processed 808000 comments\n",
      "processed 809000 comments\n",
      "processing file ecfs_17-108_22110000.json\n",
      "processed 810000 comments\n",
      "processed 811000 comments\n",
      "processed 812000 comments\n",
      "processed 813000 comments\n",
      "processed 814000 comments\n",
      "processed 815000 comments\n",
      "processed 816000 comments\n",
      "processed 817000 comments\n",
      "processed 818000 comments\n",
      "processed 819000 comments\n",
      "processing file ecfs_17-108_17770000.json\n",
      "processed 820000 comments\n",
      "processed 821000 comments\n",
      "processed 822000 comments\n",
      "processed 823000 comments\n",
      "processed 824000 comments\n",
      "processed 825000 comments\n",
      "processed 826000 comments\n",
      "processed 827000 comments\n",
      "processed 828000 comments\n",
      "processed 829000 comments\n",
      "processing file ecfs_17-108_15110000.json\n",
      "processed 830000 comments\n",
      "processed 831000 comments\n",
      "processed 832000 comments\n",
      "processed 833000 comments\n",
      "processed 834000 comments\n",
      "processed 835000 comments\n",
      "processed 836000 comments\n",
      "processed 837000 comments\n",
      "processed 838000 comments\n",
      "processed 839000 comments\n",
      "processing file ecfs_17-108_19810000.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 840000 comments\n",
      "processed 841000 comments\n",
      "processed 842000 comments\n",
      "processed 843000 comments\n",
      "processed 844000 comments\n",
      "processed 845000 comments\n",
      "processed 846000 comments\n",
      "processed 847000 comments\n",
      "processed 848000 comments\n",
      "processed 849000 comments\n",
      "processing file ecfs_17-108_15100000.json\n",
      "processed 850000 comments\n",
      "processed 851000 comments\n",
      "processed 852000 comments\n",
      "processed 853000 comments\n",
      "processed 854000 comments\n",
      "processed 855000 comments\n",
      "processed 856000 comments\n",
      "processed 857000 comments\n",
      "processed 858000 comments\n",
      "processed 859000 comments\n",
      "processing file ecfs_17-108_19800000.json\n",
      "processed 860000 comments\n",
      "processed 861000 comments\n",
      "processed 862000 comments\n",
      "processed 863000 comments\n",
      "processed 864000 comments\n",
      "processed 865000 comments\n",
      "processed 866000 comments\n",
      "processed 867000 comments\n",
      "processed 868000 comments\n",
      "processed 869000 comments\n",
      "processing file ecfs_17-108_17760000.json\n",
      "processed 870000 comments\n",
      "processed 871000 comments\n",
      "processed 872000 comments\n",
      "processed 873000 comments\n",
      "processed 874000 comments\n",
      "processed 875000 comments\n",
      "processed 876000 comments\n",
      "processed 877000 comments\n",
      "processed 878000 comments\n",
      "processed 879000 comments\n",
      "processing file ecfs_17-108_16360000.json\n",
      "processed 880000 comments\n",
      "processed 881000 comments\n",
      "processed 882000 comments\n",
      "processed 883000 comments\n",
      "processed 884000 comments\n",
      "processed 885000 comments\n",
      "processed 886000 comments\n",
      "processed 887000 comments\n",
      "processed 888000 comments\n",
      "processed 889000 comments\n",
      "processing file ecfs_17-108_16370000.json\n",
      "processed 890000 comments\n",
      "processed 891000 comments\n",
      "processed 892000 comments\n",
      "processed 893000 comments\n",
      "processed 894000 comments\n",
      "processed 895000 comments\n",
      "processed 896000 comments\n",
      "processed 897000 comments\n",
      "processed 898000 comments\n",
      "processed 899000 comments\n",
      "processing file ecfs_17-108_21370000.json\n",
      "processed 900000 comments\n",
      "processed 901000 comments\n",
      "processed 902000 comments\n",
      "processed 903000 comments\n",
      "processed 904000 comments\n",
      "processed 905000 comments\n",
      "processed 906000 comments\n",
      "processed 907000 comments\n",
      "processed 908000 comments\n",
      "processed 909000 comments\n",
      "processing file ecfs_17-108_21360000.json\n",
      "processed 910000 comments\n",
      "processed 911000 comments\n",
      "processed 912000 comments\n",
      "processed 913000 comments\n",
      "processed 914000 comments\n",
      "processed 915000 comments\n",
      "processed 916000 comments\n",
      "processed 917000 comments\n",
      "processed 918000 comments\n",
      "processed 919000 comments\n",
      "processing file ecfs_17-108_15580000.json\n",
      "processed 920000 comments\n",
      "processed 921000 comments\n",
      "processed 922000 comments\n",
      "processed 923000 comments\n",
      "processed 924000 comments\n",
      "processed 925000 comments\n",
      "processed 926000 comments\n",
      "processed 927000 comments\n",
      "processed 928000 comments\n",
      "processed 929000 comments\n",
      "processing file ecfs_17-108_15590000.json\n",
      "processed 930000 comments\n",
      "processed 931000 comments\n",
      "processed 932000 comments\n",
      "processed 933000 comments\n",
      "processed 934000 comments\n",
      "processed 935000 comments\n",
      "processed 936000 comments\n",
      "processed 937000 comments\n",
      "processed 938000 comments\n",
      "processed 939000 comments\n",
      "processing file ecfs_17-108_18520000.json\n",
      "processed 940000 comments\n",
      "processed 941000 comments\n",
      "processed 942000 comments\n",
      "processed 943000 comments\n",
      "processed 944000 comments\n",
      "processed 945000 comments\n",
      "processed 946000 comments\n",
      "processed 947000 comments\n",
      "processed 948000 comments\n",
      "processed 949000 comments\n",
      "processing file ecfs_17-108_18530000.json\n",
      "processed 950000 comments\n",
      "processed 951000 comments\n",
      "processed 952000 comments\n",
      "processed 953000 comments\n",
      "processed 954000 comments\n",
      "processed 955000 comments\n",
      "processed 956000 comments\n",
      "processed 957000 comments\n",
      "processed 958000 comments\n",
      "processed 959000 comments\n",
      "processing file ecfs_17-108_19300000.json\n",
      "processed 960000 comments\n",
      "processed 961000 comments\n",
      "processed 962000 comments\n",
      "processed 963000 comments\n",
      "processed 964000 comments\n",
      "processed 965000 comments\n",
      "processed 966000 comments\n",
      "processed 967000 comments\n",
      "processed 968000 comments\n",
      "processed 969000 comments\n",
      "processing file ecfs_17-108_19310000.json\n",
      "processed 970000 comments\n",
      "processed 971000 comments\n",
      "processed 972000 comments\n",
      "processed 973000 comments\n",
      "processed 974000 comments\n",
      "processed 975000 comments\n",
      "processed 976000 comments\n",
      "processed 977000 comments\n",
      "processed 978000 comments\n",
      "processed 979000 comments\n",
      "processing file ecfs_17-108_18380000.json\n",
      "processed 980000 comments\n",
      "processed 981000 comments\n",
      "processed 982000 comments\n",
      "processed 983000 comments\n",
      "processed 984000 comments\n",
      "processed 985000 comments\n",
      "processed 986000 comments\n",
      "processed 987000 comments\n",
      "processed 988000 comments\n",
      "processed 989000 comments\n",
      "processing file ecfs_17-108_18390000.json\n",
      "processed 990000 comments\n",
      "processed 991000 comments\n",
      "processed 992000 comments\n",
      "processed 993000 comments\n",
      "processed 994000 comments\n",
      "processed 995000 comments\n",
      "processed 996000 comments\n",
      "processed 997000 comments\n",
      "processed 998000 comments\n",
      "processed 999000 comments\n",
      "processing file ecfs_17-108_20550000.json\n",
      "processed 1000000 comments\n",
      "processing file ecfs_17-108_20540000.json\n"
     ]
    }
   ],
   "source": [
    "%pdb\n",
    "\n",
    "TOTAL_TO_PROCESS = 1000000\n",
    "COMMENT_TEXT = []\n",
    "\n",
    "processed = 0\n",
    "\n",
    "THIRD_DIR = './ECFS_17-108_3'\n",
    "for dir_, _, file_list in os.walk(THIRD_DIR):\n",
    "    for i, file in enumerate(file_list):\n",
    "        print(f'processing file #{i}: {file}')\n",
    "        if processed >= TOTAL_TO_PROCESS:\n",
    "            break\n",
    "        with open(os.path.join(THIRD_DIR, file), 'r') as f:\n",
    "            for comment in json.loads(f.read()):\n",
    "                if processed < TOTAL_TO_PROCESS:\n",
    "                    try:\n",
    "                        COMMENT_TEXT.append(comment['text_data'])\n",
    "                    except:\n",
    "                        # TODO: handle edge cases better\n",
    "                        continue\n",
    "                    processed += 1\n",
    "                else:\n",
    "                    break\n",
    "                if processed % 1000 == 0:\n",
    "                    print(f'processed {processed} comments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Cable and phone companies provide access to the internet. They're telecommunications carriers. They do not (and should not) have the right to censor or slow down my speech and my access to online content. When I use my broadband service, I decide who I communicate with and what information I transmit. I want the FCC to retain the ability to stop my internet service provider from interfering with my communications choices. The courts have already told the FCC that to do this, ISPs must remain under Title II.  \\n\\nI'm urging FCC Chairman Ajit Pai to preserve real Net Neutrality rules and keep Title II in place for broadband internet access. \""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COMMENT_TEXT[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from string import punctuation\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def find_most_common_words(text):\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "    with_stop = Counter()\n",
    "    without_stop = Counter()\n",
    "    for comment in text:\n",
    "        words = re.findall(r'\\w+', comment)\n",
    "        without_stop.update(w.lower().rstrip(punctuation) for w in words if w.lower() not in stop_words)\n",
    "    return [y for y in without_stop.most_common(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "without_stops = find_most_common_words(COMMENT_TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('internet', 2036838),\n",
       " ('title', 1146463),\n",
       " ('ii', 1146353),\n",
       " ('fcc', 1010034),\n",
       " ('government', 900923),\n",
       " ('regulations', 804693),\n",
       " ('regulatory', 772256),\n",
       " ('economy', 592854),\n",
       " ('federal', 588016),\n",
       " ('innovation', 558722),\n",
       " ('chairman', 539037),\n",
       " ('back', 530704),\n",
       " ('support', 494191),\n",
       " ('investment', 489678),\n",
       " ('open', 489609),\n",
       " ('net', 438247),\n",
       " ('neutrality', 438180),\n",
       " ('taxpayers', 411678),\n",
       " ('control', 393870),\n",
       " ('free', 386691),\n",
       " ('communications', 365326),\n",
       " ('decision', 360108),\n",
       " ('telecommunications', 359742),\n",
       " ('commission', 355876),\n",
       " ('time', 354143),\n",
       " ('allow', 345344),\n",
       " ('misguided', 345019),\n",
       " ('strong', 340470),\n",
       " ('act', 339791),\n",
       " ('favor', 339766),\n",
       " ('sincerely', 339726),\n",
       " ('hurting', 330690),\n",
       " ('scheme', 330681),\n",
       " ('pai', 330508),\n",
       " ('2015', 330035),\n",
       " ('interference', 315646),\n",
       " ('without', 303701),\n",
       " ('regulation', 301345),\n",
       " ('return', 301309),\n",
       " ('one', 243290),\n",
       " ('obama', 243058),\n",
       " ('u', 243023),\n",
       " ('roll', 243021),\n",
       " ('largest', 242997),\n",
       " ('broad', 242989),\n",
       " ('sectors', 242983),\n",
       " ('restore', 227946),\n",
       " ('commissioners', 227946),\n",
       " ('american', 225176),\n",
       " ('consumers', 225120),\n",
       " ('broadband', 222317),\n",
       " ('important', 217278),\n",
       " ('known', 213619),\n",
       " ('decades', 213618),\n",
       " ('framework', 213612),\n",
       " ('n', 212233),\n",
       " ('utility', 205929),\n",
       " ('infrastructure', 205884),\n",
       " ('truly', 205869),\n",
       " ('imposed', 205840),\n",
       " ('style', 205834),\n",
       " ('thank', 182943),\n",
       " ('market', 180309),\n",
       " ('massive', 180172),\n",
       " ('principles', 180055),\n",
       " ('digital', 180051),\n",
       " ('administration', 180043),\n",
       " ('office', 180042),\n",
       " ('policy', 180042),\n",
       " ('leaving', 180036),\n",
       " ('threatening', 180035),\n",
       " ('gave', 180034),\n",
       " ('guide', 180030),\n",
       " ('rammed', 180029),\n",
       " ('plan', 169812),\n",
       " ('tom', 165282),\n",
       " ('wheeler', 165196),\n",
       " ('hurt', 165088),\n",
       " ('cannot', 165085),\n",
       " ('past', 165040),\n",
       " ('rolling', 165022),\n",
       " ('tool', 165020),\n",
       " ('comments', 165011),\n",
       " ('agency', 165007),\n",
       " ('reach', 165006),\n",
       " ('considering', 165002),\n",
       " ('limiting', 164999),\n",
       " ('unrestricted', 164999),\n",
       " ('period', 164999),\n",
       " ('expanding', 164998),\n",
       " ('funded', 164996),\n",
       " ('restrictive', 164992),\n",
       " ('inhibited', 164992),\n",
       " ('ecosystem', 164991),\n",
       " ('revolutionary', 164991),\n",
       " ('excessive', 164991),\n",
       " ('burdensome', 164990),\n",
       " ('guise', 164990),\n",
       " ('bogged', 164989),\n",
       " ('reply', 164989)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "without_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(COMMENT_TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59974"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(COMMENT_TEXT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe we can use some sort of unsupervised sentiment analysis? This paper (http://nparc.cisti-icist.nrc-cnrc.gc.ca/eng/view/object/?id=4bb7a0c8-9d9b-4ded-bcf6-fdf64ee28ccc) shows an example by seeding with a 2-word classifier.\n",
    "\n",
    "Maybe we could do a similar thing here with \"title ii\" and... something else? Then again, maybe \"title ii\" is used in pro/anti comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the comments into for/against\n",
    "\n",
    "1M comments are comprised of ~60k unique comments. (This presents an interesting opportunity for compression! When storing these ~60 Gb of comments, maybe there's some seed of \"non-unique\" comments which are stored in a table?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
